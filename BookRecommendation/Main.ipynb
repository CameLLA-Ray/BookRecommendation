{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f29da673-f919-404e-8ba4-048134ff844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aabc2b7a-7965-4890-ab92-ddd015e83353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "users_file = 'Users.csv'\n",
    "books_file = 'Books.csv'\n",
    "ratings_file = 'Ratings.csv'\n",
    "\n",
    "# Load datasets\n",
    "try:\n",
    "    users = pd.read_csv(users_file, encoding='latin-1')\n",
    "    \n",
    "    # E: Avoid DtypeWarning by specifying 'Year-Of-Publication' as string on load\n",
    "    books = pd.read_csv(\n",
    "        books_file, \n",
    "        encoding='latin-1', \n",
    "        dtype={'Year-Of-Publication': str},  # This prevents the mixed-type warning\n",
    "        on_bad_lines='skip'\n",
    "    )\n",
    "    \n",
    "    ratings = pd.read_csv(ratings_file, encoding='latin-1')\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Ensure 'Users.csv', 'Books.csv', and 'Ratings.csv' are in the same directory.\")\n",
    "    \n",
    "print(\"Datasets loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "33d6137a-3dd2-4403-aa5f-0f12773e5d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Shapes of Datasets ---\n",
      "Users shape:   (278858, 3)\n",
      "Books shape:   (271360, 8)\n",
      "Ratings shape: (1149780, 3)\n",
      "------------------------------\n",
      "\n",
      "--- 2 & 3. Null Values per Column ---\n",
      "Books Nulls:\n",
      " ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            2\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n",
      "\n",
      "Users Nulls:\n",
      " User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n",
      "\n",
      "Ratings Nulls:\n",
      " User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      "--- 4. Creating Merged Dataset ---\n",
      "Shape of merged 'ratings_with_books': (1031136, 10)\n",
      "------------------------------\n",
      "\n",
      "--- 5. Info for 'ratings_with_books' ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1031136 entries, 0 to 1031135\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   User-ID              1031136 non-null  int64 \n",
      " 1   ISBN                 1031136 non-null  object\n",
      " 2   Book-Rating          1031136 non-null  int64 \n",
      " 3   Book-Title           1031136 non-null  object\n",
      " 4   Book-Author          1031134 non-null  object\n",
      " 5   Year-Of-Publication  1031136 non-null  object\n",
      " 6   Publisher            1031134 non-null  object\n",
      " 7   Image-URL-S          1031136 non-null  object\n",
      " 8   Image-URL-M          1031136 non-null  object\n",
      " 9   Image-URL-L          1031132 non-null  object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 78.7+ MB\n",
      "------------------------------\n",
      "\n",
      "--- 6. Unique Values in 'ratings_with_books' ---\n",
      "User-ID                 92106\n",
      "ISBN                   270151\n",
      "Book-Rating                11\n",
      "Book-Title             241071\n",
      "Book-Author            101587\n",
      "Year-Of-Publication       118\n",
      "Publisher               16729\n",
      "Image-URL-S            269842\n",
      "Image-URL-M            269842\n",
      "Image-URL-L            269839\n",
      "dtype: int64\n",
      "------------------------------\n",
      "\n",
      "--- 7. Data Types of 'ratings_with_books' ---\n",
      "User-ID                 int64\n",
      "ISBN                   object\n",
      "Book-Rating             int64\n",
      "Book-Title             object\n",
      "Book-Author            object\n",
      "Year-Of-Publication    object\n",
      "Publisher              object\n",
      "Image-URL-S            object\n",
      "Image-URL-M            object\n",
      "Image-URL-L            object\n",
      "dtype: object\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Display the shape of the datasets ---\n",
    "print(\"--- 1. Shapes of Datasets ---\")\n",
    "print(f\"Users shape:   {users.shape}\")\n",
    "print(f\"Books shape:   {books.shape}\")\n",
    "print(f\"Ratings shape: {ratings.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. & 3. Display total nulls and detect null cols ---\n",
    "print(\"\\n--- 2 & 3. Null Values per Column ---\")\n",
    "print(\"Books Nulls:\\n\", books.isnull().sum())\n",
    "print(\"\\nUsers Nulls:\\n\", users.isnull().sum())\n",
    "print(\"\\nRatings Nulls:\\n\", ratings.isnull().sum())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 4. Create the comparison dataset ---\n",
    "# Merge ratings with books for a combined view\n",
    "print(\"\\n--- 4. Creating Merged Dataset ---\")\n",
    "ratings_with_books = ratings.merge(books, on='ISBN')\n",
    "print(f\"Shape of merged 'ratings_with_books': {ratings_with_books.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 5. Display information about dataset ---\n",
    "print(\"\\n--- 5. Info for 'ratings_with_books' ---\")\n",
    "ratings_with_books.info()\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 6. Display number of unique values ---\n",
    "print(\"\\n--- 6. Unique Values in 'ratings_with_books' ---\")\n",
    "print(ratings_with_books.nunique())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 7. Display the data types ---\n",
    "print(\"\\n--- 7. Data Types of 'ratings_with_books' ---\")\n",
    "print(ratings_with_books.dtypes)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e040ac38-8c65-4e66-b56e-612e12cfac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "Books shape after cleaning: (266723, 5)\n",
      "Users shape after cleaning: (278858, 2)\n",
      "Explicit ratings shape: (433671, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86183\\AppData\\Local\\Temp\\ipykernel_62260\\316589046.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  books['Book-Author'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\86183\\AppData\\Local\\Temp\\ipykernel_62260\\316589046.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  books['Publisher'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- Preprocessing 'Books' Dataset ---\n",
    "\n",
    "# C: Drop unnecessary image URL columns\n",
    "books.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis=1, inplace=True)\n",
    "\n",
    "# B: Clean 'Year-Of-Publication'\n",
    "# Convert to numeric, forcing errors (like strings) to NaN\n",
    "books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# B: Filter out rows with invalid or NaN years instead of filling them\n",
    "# Keep only books published in a reasonable range (e.g., 1900-2025)\n",
    "books = books[\n",
    "    (books['Year-Of-Publication'] >= 1900) &\n",
    "    (books['Year-Of-Publication'] <= 2025)\n",
    "]\n",
    "\n",
    "# Fill the few remaining NaN values in text columns\n",
    "books['Book-Author'].fillna('Unknown', inplace=True)\n",
    "books['Publisher'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "# --- Preprocessing 'Users' Dataset ---\n",
    "# A: Drop the 'Age' column\n",
    "# The 'Age' column has too many (over 39%) null values to be reliable\n",
    "users.drop('Age', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# --- Preprocessing 'Ratings' Dataset ---\n",
    "# We only want explicit ratings (1-10) for this model, not implicit (0)\n",
    "explicit_ratings = ratings[ratings['Book-Rating'] != 0]\n",
    "\n",
    "print(\"Preprocessing complete.\")\n",
    "print(f\"Books shape after cleaning: {books.shape}\")\n",
    "print(f\"Users shape after cleaning: {users.shape}\")\n",
    "print(f\"Explicit ratings shape: {explicit_ratings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2c7012ee-1fb9-4539-98c3-940a5889a2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Examine Data Characteristics & Distributions ---\n",
    "\n",
    "# 1.1 Distribution of Explicit Book Ratings (1-10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Book-Rating', data=explicit_ratings)\n",
    "plt.title('Distribution of Explicit Book Ratings (1-10)')\n",
    "plt.show()\n",
    "\n",
    "# 1.2 Distribution of Publication Year (Post-Cleaning)\n",
    "plt.figure(figsize=(12, 6))\n",
    "# We can now safely plot the cleaned numeric column\n",
    "sns.histplot(books['Year-Of-Publication'], bins=50, kde=False)\n",
    "plt.title('Distribution of Publication Year (1900-2025)')\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "222cee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7242\n",
      "Test set size: 1811\n",
      "Unique users in train: 1047\n",
      "Unique users in test: 744\n"
     ]
    }
   ],
   "source": [
    "# --- Split data into train and test sets for evaluation ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data: 80% train, 20% test\n",
    "train_df, test_df = train_test_split(filtered_final_df, test_size=0.2, random_state=42, stratify=None)\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "print(f\"Unique users in train: {train_df['user_encoded'].nunique()}\")\n",
    "print(f\"Unique users in test: {test_df['user_encoded'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6e21b204-9cd1-4b16-939c-7af59302e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ratings: 378031\n",
      "Filtered ratings for model: 9053\n",
      "Unique users for model: 1063\n",
      "Unique books for model: 198\n",
      "\n",
      "Final data head with encoded features:\n",
      "     User-ID        ISBN  Book-Rating  \\\n",
      "517   277427  0061009059            9   \n",
      "528   277427  0316776963            8   \n",
      "535   277427  0385424736            9   \n",
      "536   277427  0385486804            9   \n",
      "538   277427  0385504209            8   \n",
      "\n",
      "                                            Book-Title      Book-Author  \\\n",
      "517  One for the Money (Stephanie Plum Novels (Pape...  Janet Evanovich   \n",
      "528                             Me Talk Pretty One Day    David Sedaris   \n",
      "535                                      The Rainmaker     John Grisham   \n",
      "536                                      Into the Wild     Jon Krakauer   \n",
      "538                                  The Da Vinci Code        Dan Brown   \n",
      "\n",
      "     Year-Of-Publication        Publisher  user_encoded  book_encoded  \n",
      "517               1995.0      HarperTorch          1059            91  \n",
      "528               2001.0   Back Bay Books          1059            81  \n",
      "535               1995.0  Doubleday Books          1059           166  \n",
      "536               1997.0           Anchor          1059            73  \n",
      "538               2003.0        Doubleday          1059           132  \n"
     ]
    }
   ],
   "source": [
    "# --- Create Final Dataset by Reducing Sparsity ---\n",
    "# To build a reliable model, we filter for active users and popular books\n",
    "\n",
    "# Merge cleaned dataframes\n",
    "final_df = explicit_ratings.merge(books, on='ISBN')\n",
    "\n",
    "# Get counts of ratings per book and per user\n",
    "book_rating_counts = final_df['Book-Title'].value_counts()\n",
    "user_rating_counts = final_df['User-ID'].value_counts()\n",
    "\n",
    "# --- D: Sparsity Thresholds ---\n",
    "# Set thresholds to filter out \"noisy\" data\n",
    "# We use higher thresholds (like in the reference file) for a more robust model\n",
    "MIN_BOOK_RATINGS = 100  # Keep books with at least 100 ratings\n",
    "MIN_USER_RATINGS = 50   # Keep users who have given at least 50 ratings\n",
    "# --- End of Thresholds ---\n",
    "\n",
    "# Filter books and users based on the thresholds\n",
    "popular_books = book_rating_counts[book_rating_counts >= MIN_BOOK_RATINGS].index\n",
    "active_users = user_rating_counts[user_rating_counts >= MIN_USER_RATINGS].index\n",
    "\n",
    "# Create the final filtered dataframe\n",
    "# E: Use .copy() to explicitly create a new DataFrame and avoid SettingWithCopyWarning\n",
    "filtered_final_df = final_df[\n",
    "    (final_df['Book-Title'].isin(popular_books)) &\n",
    "    (final_df['User-ID'].isin(active_users))\n",
    "].copy()\n",
    "\n",
    "print(f\"Original ratings: {len(final_df)}\")\n",
    "print(f\"Filtered ratings for model: {len(filtered_final_df)}\")\n",
    "print(f\"Unique users for model: {filtered_final_df['User-ID'].nunique()}\")\n",
    "print(f\"Unique books for model: {filtered_final_df['Book-Title'].nunique()}\")\n",
    "\n",
    "# --- Feature Encoding ---\n",
    "# Convert User-ID and ISBN to continuous integer indices for the model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "book_enc = LabelEncoder()\n",
    "\n",
    "# No warnings will be triggered here\n",
    "filtered_final_df['user_encoded'] = user_enc.fit_transform(filtered_final_df['User-ID'])\n",
    "filtered_final_df['book_encoded'] = book_enc.fit_transform(filtered_final_df['Book-Title'])\n",
    "\n",
    "print(\"\\nFinal data head with encoded features:\")\n",
    "print(filtered_final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "63896a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics functions defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation Metrics: Precision@K, Recall@K, NDCG@K ---\n",
    "\n",
    "def precision_at_k(recommended, ground_truth, k):\n",
    "    \"\"\"\n",
    "    Calculate Precision@K\n",
    "    recommended: list of recommended item indices\n",
    "    ground_truth: list of ground truth item indices\n",
    "    k: top-K items to consider\n",
    "    \"\"\"\n",
    "    if len(recommended) > k:\n",
    "        recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(ground_truth))\n",
    "    return hits / k if k > 0 else 0.0\n",
    "\n",
    "\n",
    "def recall_at_k(recommended, ground_truth, k):\n",
    "    \"\"\"\n",
    "    Calculate Recall@K\n",
    "    recommended: list of recommended item indices\n",
    "    ground_truth: list of ground truth item indices\n",
    "    k: top-K items to consider\n",
    "    \"\"\"\n",
    "    if len(ground_truth) == 0:\n",
    "        return 0.0\n",
    "    if len(recommended) > k:\n",
    "        recommended = recommended[:k]\n",
    "    hits = len(set(recommended) & set(ground_truth))\n",
    "    return hits / len(ground_truth)\n",
    "\n",
    "\n",
    "def dcg_at_k(recommended, ground_truth, k):\n",
    "    \"\"\"\n",
    "    Calculate DCG@K (Discounted Cumulative Gain)\n",
    "    \"\"\"\n",
    "    recommended = recommended[:k]\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended):\n",
    "        if item in ground_truth:\n",
    "            dcg += 1.0 / np.log2(i + 2)  # i starts at 0, so i+2\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def idcg_at_k(ground_truth, k):\n",
    "    \"\"\"\n",
    "    Calculate IDCG@K (Ideal DCG when all ground truth items are at top)\n",
    "    \"\"\"\n",
    "    ideal_hits = min(len(ground_truth), k)\n",
    "    if ideal_hits == 0:\n",
    "        return 0.0\n",
    "    idcg = sum((1.0 / np.log2(i + 2)) for i in range(ideal_hits))\n",
    "    return idcg\n",
    "\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, k):\n",
    "    \"\"\"\n",
    "    Calculate NDCG@K (Normalized Discounted Cumulative Gain)\n",
    "    \"\"\"\n",
    "    idcg = idcg_at_k(ground_truth, k)\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg_at_k(recommended, ground_truth, k) / idcg\n",
    "\n",
    "\n",
    "def evaluate_recommendations(recommendations_dict, test_df, k=10):\n",
    "    \"\"\"\n",
    "    Evaluate recommendations for all users in test set\n",
    "    recommendations_dict: dict mapping user_encoded to list of recommended book_encoded\n",
    "    test_df: test dataframe with user_encoded and book_encoded columns\n",
    "    k: top-K for evaluation\n",
    "    Returns: average precision, recall, ndcg\n",
    "    \"\"\"\n",
    "    # Build ground truth per user from test_df\n",
    "    ground_truth = test_df.groupby('user_encoded')['book_encoded'].apply(list).to_dict()\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    for user_encoded, recommended_items in recommendations_dict.items():\n",
    "        if user_encoded in ground_truth:\n",
    "            gt_items = ground_truth[user_encoded]\n",
    "            precisions.append(precision_at_k(recommended_items, gt_items, k))\n",
    "            recalls.append(recall_at_k(recommended_items, gt_items, k))\n",
    "            ndcgs.append(ndcg_at_k(recommended_items, gt_items, k))\n",
    "    \n",
    "    avg_precision = np.mean(precisions) if precisions else 0.0\n",
    "    avg_recall = np.mean(recalls) if recalls else 0.0\n",
    "    avg_ndcg = np.mean(ndcgs) if ndcgs else 0.0\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_ndcg\n",
    "\n",
    "print(\"Evaluation metrics functions defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76434353",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "PrecisionRecallNDCG\n",
    "\n",
    "1. ****\n",
    "2. ****510\n",
    "3. ****\n",
    "   - LightGBM: \n",
    "   - BPR: embedding\n",
    "4. ****CF\n",
    "5. **K**K=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "931ffe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import difflib\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "92a0a65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative Filtering model trained. Similarity matrix shape: (198, 198)\n",
      "\n",
      "=== Collaborative Filtering Evaluation ===\n",
      "Evaluated 728 users\n",
      "K=5: Precision@5: 0.0481, Recall@5: 0.1192, NDCG@5: 0.1054\n",
      "K=10: Precision@10: 0.0342, Recall@10: 0.1673, NDCG@10: 0.1233\n",
      "K=20: Precision@20: 0.0223, Recall@20: 0.2121, NDCG@20: 0.1372\n"
     ]
    }
   ],
   "source": [
    "# --- Algorithms Definition: 1. Item-based Collaborative Filtering ()---\n",
    "def collaborative_filtering(df):\n",
    "    \"\"\"\n",
    "    Implements item-based CF using cosine similarity with user mean normalization.\n",
    "    This helps handle user bias and improves recommendation quality.\n",
    "    \"\"\"\n",
    "    # Create user-book rating matrix\n",
    "    user_book_matrix = df.pivot_table(index='user_encoded', columns='book_encoded', values='Book-Rating').fillna(0)\n",
    "    \n",
    "    # Calculate user means for normalization\n",
    "    user_means = user_book_matrix.mean(axis=1)\n",
    "    \n",
    "    # Normalize by user mean (centering) to handle user bias\n",
    "    user_book_matrix_normalized = user_book_matrix.sub(user_means, axis=0)\n",
    "    \n",
    "    # Compute similarity between books using normalized matrix\n",
    "    # This gives better similarity scores by removing user bias\n",
    "    book_similarity = cosine_similarity(user_book_matrix_normalized.T)\n",
    "    book_similarity_df = pd.DataFrame(book_similarity, index=user_book_matrix.columns, columns=user_book_matrix.columns)\n",
    "    \n",
    "    return book_similarity_df, user_book_matrix, user_means\n",
    "\n",
    "# Train CF model on training data\n",
    "cf_similarity_df, cf_user_book_matrix, cf_user_means = collaborative_filtering(train_df)\n",
    "print(\"Collaborative Filtering model trained. Similarity matrix shape:\", cf_similarity_df.shape)\n",
    "\n",
    "# Generate recommendations for CF ()\n",
    "def recommend_cf_for_user(user_encoded, user_book_matrix, similarity_df, user_means=None, train_interactions=None, n=20):\n",
    "    \"\"\"Generate recommendations for a user using item-based CF with improved scoring\"\"\"\n",
    "    user_ratings = user_book_matrix.loc[user_encoded]\n",
    "    user_mean = user_means.loc[user_encoded] if user_means is not None else user_ratings[user_ratings > 0].mean()\n",
    "    \n",
    "    # Get books the user has already rated in training set\n",
    "    rated_books = user_ratings[user_ratings > 0].index.tolist()\n",
    "    \n",
    "    if len(rated_books) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Calculate weighted scores for all books with improved formula\n",
    "    scores = {}\n",
    "    for book_idx in similarity_df.index:\n",
    "        # Exclude books already rated in training set\n",
    "        if book_idx not in rated_books:\n",
    "            score = 0\n",
    "            total_sim = 0\n",
    "            for rated_book in rated_books:\n",
    "                similarity = similarity_df.loc[book_idx, rated_book]\n",
    "                # Only consider positive similarities (more reliable)\n",
    "                if similarity > 0.1:  # Threshold to filter weak similarities\n",
    "                    rating = user_ratings[rated_book]\n",
    "                    # Use centered rating (rating - user_mean) for better prediction\n",
    "                    centered_rating = rating - user_mean if not pd.isna(user_mean) else rating\n",
    "                    score += similarity * centered_rating\n",
    "                    total_sim += similarity\n",
    "            \n",
    "            # Normalize and add user mean back\n",
    "            if total_sim > 0:\n",
    "                predicted_rating = (score / total_sim) + user_mean\n",
    "                # Use similarity as confidence weight\n",
    "                confidence = min(total_sim / len(rated_books), 1.0)\n",
    "                scores[book_idx] = predicted_rating * confidence\n",
    "            else:\n",
    "                # Fallback to user mean if no similar books\n",
    "                scores[book_idx] = user_mean if not pd.isna(user_mean) else 0\n",
    "    \n",
    "    # Get top N recommendations\n",
    "    top_books = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    return [book_idx for book_idx, _ in top_books]\n",
    "\n",
    "# Evaluate CF model\n",
    "# Only evaluate users that exist in training set\n",
    "train_users = set(cf_user_book_matrix.index)\n",
    "test_users = set(test_df['user_encoded'].unique())\n",
    "users_to_evaluate = train_users & test_users  # Intersection: users in both train and test\n",
    "\n",
    "cf_recommendations = {}\n",
    "for user_encoded in users_to_evaluate:\n",
    "    try:\n",
    "        recs = recommend_cf_for_user(user_encoded, cf_user_book_matrix, cf_similarity_df, cf_user_means, n=20)\n",
    "        if len(recs) > 0:\n",
    "            cf_recommendations[user_encoded] = recs\n",
    "    except KeyError:\n",
    "        continue  # Skip users not in training matrix\n",
    "\n",
    "# Filter test_df to only include users we evaluated\n",
    "test_df_cf = test_df[test_df['user_encoded'].isin(users_to_evaluate)].copy()\n",
    "\n",
    "if len(cf_recommendations) > 0:\n",
    "    # Evaluate at multiple K values for comprehensive analysis\n",
    "    print(f\"\\n=== Collaborative Filtering Evaluation ===\")\n",
    "    print(f\"Evaluated {len(cf_recommendations)} users\")\n",
    "    for k in [5, 10, 20]:\n",
    "        cf_precision, cf_recall, cf_ndcg = evaluate_recommendations(cf_recommendations, test_df_cf, k)\n",
    "        print(f\"K={k}: Precision@{k}: {cf_precision:.4f}, Recall@{k}: {cf_recall:.4f}, NDCG@{k}: {cf_ndcg:.4f}\")\n",
    "else:\n",
    "    print(\"\\n=== Collaborative Filtering Evaluation ===\")\n",
    "    print(\"No users to evaluate (no overlap between train and test users)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c9b25265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 1.62323\n",
      "[100]\tvalid_0's rmse: 1.57322\n",
      "[150]\tvalid_0's rmse: 1.54881\n",
      "[200]\tvalid_0's rmse: 1.53704\n",
      "[250]\tvalid_0's rmse: 1.53526\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's rmse: 1.5349\n",
      "LightGBM RMSE: 1.5349026660814826\n",
      "\n",
      "=== LightGBM Evaluation ===\n",
      "Evaluated 728 users\n",
      "K=5: Precision@5: 0.0212, Recall@5: 0.0411, NDCG@5: 0.0328\n",
      "K=10: Precision@10: 0.0166, Recall@10: 0.0683, NDCG@10: 0.0426\n",
      "K=20: Precision@20: 0.0167, Recall@20: 0.1369, NDCG@20: 0.0640\n"
     ]
    }
   ],
   "source": [
    "# --- Algorithms Definition: 2. LightGBM ()---\n",
    "def lightgbm_model(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Uses LightGBM for rating prediction (regression) with enhanced features.\n",
    "    \"\"\"\n",
    "    # =====  =====\n",
    "    # User average rating\n",
    "    user_avg_rating = train_df.groupby('user_encoded')['Book-Rating'].mean().to_dict()\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "    train_df['user_avg_rating'] = train_df['user_encoded'].map(user_avg_rating)\n",
    "    test_df['user_avg_rating'] = test_df['user_encoded'].map(user_avg_rating).fillna(train_df['Book-Rating'].mean())\n",
    "    \n",
    "    # Book average rating\n",
    "    book_avg_rating = train_df.groupby('book_encoded')['Book-Rating'].mean().to_dict()\n",
    "    train_df['book_avg_rating'] = train_df['book_encoded'].map(book_avg_rating)\n",
    "    test_df['book_avg_rating'] = test_df['book_encoded'].map(book_avg_rating).fillna(train_df['Book-Rating'].mean())\n",
    "    \n",
    "    # User rating count (popularity)\n",
    "    user_rating_count = train_df.groupby('user_encoded').size().to_dict()\n",
    "    train_df['user_rating_count'] = train_df['user_encoded'].map(user_rating_count)\n",
    "    test_df['user_rating_count'] = test_df['user_encoded'].map(user_rating_count).fillna(0)\n",
    "    \n",
    "    # Book rating count (popularity)\n",
    "    book_rating_count = train_df.groupby('book_encoded').size().to_dict()\n",
    "    train_df['book_rating_count'] = train_df['book_encoded'].map(book_rating_count)\n",
    "    test_df['book_rating_count'] = test_df['book_encoded'].map(book_rating_count).fillna(0)\n",
    "    \n",
    "    # User rating std (variance in user preferences)\n",
    "    user_rating_std = train_df.groupby('user_encoded')['Book-Rating'].std().fillna(0).to_dict()\n",
    "    train_df['user_rating_std'] = train_df['user_encoded'].map(user_rating_std)\n",
    "    test_df['user_rating_std'] = test_df['user_encoded'].map(user_rating_std).fillna(0)\n",
    "    \n",
    "    # Book rating std (controversy)\n",
    "    book_rating_std = train_df.groupby('book_encoded')['Book-Rating'].std().fillna(0).to_dict()\n",
    "    train_df['book_rating_std'] = train_df['book_encoded'].map(book_rating_std)\n",
    "    test_df['book_rating_std'] = test_df['book_encoded'].map(book_rating_std).fillna(0)\n",
    "    \n",
    "    features = ['user_encoded', 'book_encoded', 'user_avg_rating', 'book_avg_rating', \n",
    "                'user_rating_count', 'book_rating_count', 'user_rating_std', 'book_rating_std']\n",
    "    target = 'Book-Rating'\n",
    "    \n",
    "    # Prepare datasets\n",
    "    train_data = lgb.Dataset(train_df[features], label=train_df[target])\n",
    "    test_data = lgb.Dataset(test_df[features], label=test_df[target], reference=train_data)\n",
    "    \n",
    "    # Parameters - \n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': 0.005,  # \n",
    "        'num_leaves': 127,  # \n",
    "        'max_depth': 8,\n",
    "        'min_data_in_leaf': 15,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 3,\n",
    "        'lambda_l1': 0.1,  # L1\n",
    "        'lambda_l2': 0.1,  # L2\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Train model with more rounds and early stopping\n",
    "    model = lgb.train(params, train_data, num_boost_round=500, valid_sets=[test_data], \n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=30), lgb.log_evaluation(period=50)])\n",
    "    \n",
    "    # Evaluate RMSE\n",
    "    test_df_copy = test_df.copy()\n",
    "    test_df_copy['predicted'] = model.predict(test_df_copy[features])\n",
    "    rmse = np.sqrt(mean_squared_error(test_df_copy[target], test_df_copy['predicted']))\n",
    "    print(\"LightGBM RMSE:\", rmse)\n",
    "    \n",
    "    return model, train_df, test_df  # Return dataframes with features for recommendation\n",
    "\n",
    "# Train LightGBM model\n",
    "lgb_model, train_df_with_features, test_df_with_features = lightgbm_model(train_df, test_df)\n",
    "\n",
    "# Generate recommendations for LightGBM ()\n",
    "def recommend_lgb_for_user(user_encoded, model, all_books, train_df_with_features, train_interactions=None, n=20):\n",
    "    \"\"\"Generate recommendations for a user using LightGBM with enhanced features\"\"\"\n",
    "    # Get books user has already rated in training set\n",
    "    if train_interactions is not None:\n",
    "        user_rated_books = set(train_interactions.get(user_encoded, []))\n",
    "    else:\n",
    "        user_rated_books = set()\n",
    "    \n",
    "    # Get user features from training data\n",
    "    user_features = train_df_with_features[train_df_with_features['user_encoded'] == user_encoded].iloc[0] if len(train_df_with_features[train_df_with_features['user_encoded'] == user_encoded]) > 0 else None\n",
    "    \n",
    "    if user_features is None:\n",
    "        return []\n",
    "    \n",
    "    # Get book features for all books\n",
    "    book_features_dict = train_df_with_features.groupby('book_encoded').first().to_dict('index')\n",
    "    \n",
    "    # Prepare feature matrix for prediction\n",
    "    feature_data = []\n",
    "    valid_books = []\n",
    "    for book_idx in all_books:\n",
    "        if book_idx not in user_rated_books and book_idx in book_features_dict:\n",
    "            book_feat = book_features_dict[book_idx]\n",
    "            feature_data.append({\n",
    "                'user_encoded': user_encoded,\n",
    "                'book_encoded': book_idx,\n",
    "                'user_avg_rating': user_features['user_avg_rating'],\n",
    "                'book_avg_rating': book_feat['book_avg_rating'],\n",
    "                'user_rating_count': user_features['user_rating_count'],\n",
    "                'book_rating_count': book_feat['book_rating_count'],\n",
    "                'user_rating_std': user_features['user_rating_std'],\n",
    "                'book_rating_std': book_feat['book_rating_std']\n",
    "            })\n",
    "            valid_books.append(book_idx)\n",
    "    \n",
    "    if len(feature_data) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Predict ratings\n",
    "    preds = model.predict(pd.DataFrame(feature_data))\n",
    "    \n",
    "    # Create list of (book_idx, score) pairs\n",
    "    book_scores = [(valid_books[i], preds[i]) for i in range(len(valid_books))]\n",
    "    \n",
    "    # Sort by score and get top N\n",
    "    book_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [book_idx for book_idx, _ in book_scores[:n]]\n",
    "\n",
    "# Evaluate LightGBM model\n",
    "# Build training interactions for each user (to exclude from recommendations)\n",
    "train_interactions = train_df.groupby('user_encoded')['book_encoded'].apply(list).to_dict()\n",
    "\n",
    "all_books = np.arange(filtered_final_df['book_encoded'].nunique())\n",
    "lgb_recommendations = {}\n",
    "for user_encoded in test_df['user_encoded'].unique():\n",
    "    try:\n",
    "        recs = recommend_lgb_for_user(user_encoded, lgb_model, all_books, train_df_with_features, train_interactions, n=20)\n",
    "        if len(recs) > 0:\n",
    "            lgb_recommendations[user_encoded] = recs\n",
    "    except Exception as e:\n",
    "        continue  # Skip users that cause errors\n",
    "\n",
    "if len(lgb_recommendations) > 0:\n",
    "    # Evaluate at multiple K values\n",
    "    print(f\"\\n=== LightGBM Evaluation ===\")\n",
    "    print(f\"Evaluated {len(lgb_recommendations)} users\")\n",
    "    for k in [5, 10, 20]:\n",
    "        lgb_precision, lgb_recall, lgb_ndcg = evaluate_recommendations(lgb_recommendations, test_df, k)\n",
    "        print(f\"K={k}: Precision@{k}: {lgb_precision:.4f}, Recall@{k}: {lgb_recall:.4f}, NDCG@{k}: {lgb_ndcg:.4f}\")\n",
    "else:\n",
    "    print(\"\\n=== LightGBM Evaluation ===\")\n",
    "    print(\"No users to evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "09dd7f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BPR: epochs=100, batch_size=256, lr=0.01, embedding_dim=64\n",
      "Epoch 1/100, Loss: 0.6933\n",
      "Epoch 10/100, Loss: 0.6931\n",
      "Early stopping at epoch 17\n",
      "\n",
      "=== BPR Evaluation ===\n",
      "Evaluated 728 users\n",
      "K=5: Precision@5: 0.0154, Recall@5: 0.0359, NDCG@5: 0.0283\n",
      "K=10: Precision@10: 0.0148, Recall@10: 0.0650, NDCG@10: 0.0396\n",
      "K=20: Precision@20: 0.0152, Recall@20: 0.1305, NDCG@20: 0.0598\n"
     ]
    }
   ],
   "source": [
    "# --- Algorithms Definition: 3. BPR (Bayesian Personalized Ranking from Reference) ---\n",
    "class BPRDataset(Dataset):\n",
    "    def __init__(self, df, user_mapping, item_mapping):\n",
    "        # Map original IDs to continuous indices starting from 0\n",
    "        self.users = df['user_encoded'].map(user_mapping).values\n",
    "        self.pos_items = df['book_encoded'].map(item_mapping).values\n",
    "        self.num_items = len(item_mapping)\n",
    "        \n",
    "        # Build item popularity for better negative sampling\n",
    "        item_counts = df['book_encoded'].value_counts().to_dict()\n",
    "        self.item_popularity = np.array([item_counts.get(item, 0) for item in sorted(item_mapping.keys())])\n",
    "        # Normalize popularity for sampling weights\n",
    "        self.item_weights = self.item_popularity / (self.item_popularity.sum() + 1e-8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.users[idx]\n",
    "        pos_item = self.pos_items[idx]\n",
    "        # Improved negative sampling: sample from less popular items (hard negatives)\n",
    "        neg_item = np.random.choice(self.num_items, p=self.item_weights)\n",
    "        return torch.tensor(user, dtype=torch.long), torch.tensor(pos_item, dtype=torch.long), torch.tensor(neg_item, dtype=torch.long)\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embedding_dim)\n",
    "        # Initialize embeddings with Xavier uniform for better convergence\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_vec = self.user_emb(user)\n",
    "        item_vec = self.item_emb(item)\n",
    "        return (user_vec * item_vec).sum(1)\n",
    "\n",
    "def train_bpr_model(df, epochs=100, batch_size=256, lr=0.01, embedding_dim=64):\n",
    "    # Create mappings from original IDs to continuous indices (0 to n-1)\n",
    "    unique_users = sorted(df['user_encoded'].unique())\n",
    "    unique_items = sorted(df['book_encoded'].unique())\n",
    "    \n",
    "    user_mapping = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "    item_mapping = {iid: idx for idx, iid in enumerate(unique_items)}\n",
    "    \n",
    "    num_users = len(unique_users)\n",
    "    num_items = len(unique_items)\n",
    "    \n",
    "    model = MF(num_users, num_items, embedding_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)  # Add weight decay for regularization\n",
    "    \n",
    "    dataset = BPRDataset(df, user_mapping, item_mapping)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    print(f\"Training BPR: epochs={epochs}, batch_size={batch_size}, lr={lr}, embedding_dim={embedding_dim}\")\n",
    "    best_loss = float('inf')\n",
    "    patience = 15\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for user, pos, neg in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            pos_score = model(user, pos)\n",
    "            neg_score = model(user, neg)\n",
    "            loss = -torch.log(torch.sigmoid(pos_score - neg_score) + 1e-8).mean()  # Add epsilon for numerical stability\n",
    "            loss.backward()\n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        if epoch == 50:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.1\n",
    "        if epoch == 80:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * 0.01\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    # Return model and mappings for later use\n",
    "    return model, user_mapping, item_mapping\n",
    "\n",
    "# Train BPR model on training data\n",
    "bpr_model, bpr_user_mapping, bpr_item_mapping = train_bpr_model(train_df)\n",
    "\n",
    "# Generate recommendations for BPR\n",
    "def recommend_bpr_for_user(user_encoded, model, all_books, user_mapping, item_mapping, train_interactions=None, n=20):\n",
    "    \"\"\"Generate recommendations for a user using BPR\"\"\"\n",
    "    # Check if user exists in training set\n",
    "    if user_encoded not in user_mapping:\n",
    "        return []\n",
    "    \n",
    "    # Map user to continuous index\n",
    "    user_idx = user_mapping[user_encoded]\n",
    "    user_tensor = torch.tensor(user_idx, dtype=torch.long)\n",
    "    \n",
    "    # Get books user has already rated in training set\n",
    "    if train_interactions is not None:\n",
    "        user_rated_books = set(train_interactions.get(user_encoded, []))\n",
    "    else:\n",
    "        user_rated_books = set()\n",
    "    \n",
    "    # Map all books to continuous indices and filter to only those in training set\n",
    "    # Also exclude books already rated by user\n",
    "    mapped_books = []\n",
    "    original_book_ids = []\n",
    "    for book_id in all_books:\n",
    "        if book_id in item_mapping and book_id not in user_rated_books:\n",
    "            mapped_books.append(item_mapping[book_id])\n",
    "            original_book_ids.append(book_id)\n",
    "    \n",
    "    if len(mapped_books) == 0:\n",
    "        return []\n",
    "    \n",
    "    books_tensor = torch.tensor(mapped_books, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        user_repeated = user_tensor.repeat(len(books_tensor))\n",
    "        scores = model(user_repeated, books_tensor)\n",
    "    top_indices = torch.argsort(scores, descending=True)[:n]\n",
    "    # Return original book IDs\n",
    "    return [original_book_ids[idx] for idx in top_indices.numpy()]\n",
    "\n",
    "# Evaluate BPR model\n",
    "# Build training interactions for each user (to exclude from recommendations)\n",
    "train_interactions = train_df.groupby('user_encoded')['book_encoded'].apply(list).to_dict()\n",
    "\n",
    "all_books = np.arange(filtered_final_df['book_encoded'].nunique())\n",
    "bpr_recommendations = {}\n",
    "for user_encoded in test_df['user_encoded'].unique():\n",
    "    try:\n",
    "        recs = recommend_bpr_for_user(user_encoded, bpr_model, all_books, bpr_user_mapping, bpr_item_mapping, train_interactions, n=20)\n",
    "        if len(recs) > 0:  # Only add if we have recommendations\n",
    "            bpr_recommendations[user_encoded] = recs\n",
    "    except Exception as e:\n",
    "        continue  # Skip users that cause errors\n",
    "\n",
    "if len(bpr_recommendations) > 0:\n",
    "    # Evaluate at multiple K values\n",
    "    print(f\"\\n=== BPR Evaluation ===\")\n",
    "    print(f\"Evaluated {len(bpr_recommendations)} users\")\n",
    "    for k in [5, 10, 20]:\n",
    "        bpr_precision, bpr_recall, bpr_ndcg = evaluate_recommendations(bpr_recommendations, test_df, k)\n",
    "        print(f\"K={k}: Precision@{k}: {bpr_precision:.4f}, Recall@{k}: {bpr_recall:.4f}, NDCG@{k}: {bpr_ndcg:.4f}\")\n",
    "else:\n",
    "    print(\"\\n=== BPR Evaluation ===\")\n",
    "    print(\"No users to evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3a3e968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 'One for the Monney (Stephanie Plum Novels' to 'One for the Money (Stephanie Plum Novels (Paperback))'\n",
      "CF Recommendations for fuzzy input: ['Two for the Dough' 'Seven Up (A Stephanie Plum Novel)'\n",
      " 'Four To Score (A Stephanie Plum Novel)' '1st to Die: A Novel'\n",
      " \"White Oleander : A Novel (Oprah's Book Club)\"]\n"
     ]
    }
   ],
   "source": [
    "def fuzzy_find_book_title(input_title, available_titles, cutoff=0.5):\n",
    "    \"\"\"\n",
    "    Finds the closest matching book title using difflib.\n",
    "    - cutoff: Similarity threshold (0-1); lower allows looser matches.\n",
    "    \"\"\"\n",
    "    matches = difflib.get_close_matches(input_title, available_titles, n=1, cutoff=cutoff)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Updated recommend_cf with fuzzy query support\n",
    "def recommend_cf(book_title, n=5):\n",
    "    available_titles = book_enc.classes_\n",
    "    matched_title = fuzzy_find_book_title(book_title, available_titles)\n",
    "    if matched_title is None:\n",
    "        return \"No matching book found (try a closer title)\"\n",
    "    print(f\"Matched '{book_title}' to '{matched_title}'\")  # Optional: Log the match\n",
    "    book_id = book_enc.transform([matched_title])[0]\n",
    "    similar_books = cf_similarity_df[book_id].sort_values(ascending=False)[1:n+1].index\n",
    "    return book_enc.inverse_transform(similar_books)\n",
    "\n",
    "# Example test with fuzzy input\n",
    "fuzzy_book = \"One for the Monney (Stephanie Plum Novels\"  # Partial/misspelled\n",
    "print(\"CF Recommendations for fuzzy input:\", recommend_cf(fuzzy_book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "73da43de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF Recommendations for One for the Money (Stephanie Plum Novels (Paperback)) : ['Two for the Dough' 'Seven Up (A Stephanie Plum Novel)'\n",
      " 'Four To Score (A Stephanie Plum Novel)' '1st to Die: A Novel'\n",
      " \"White Oleander : A Novel (Oprah's Book Club)\"]\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (2) is not the same as it was in training data (8).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\_Desktop\\CU-DG\\2025-SemA\\CS5481 Data Engineering\\BookRecommendation\\BookRecommendation\\Main.ipynb  15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Example: Recommend for a user using LightGBM and BPR\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m example_user \u001b[39m=\u001b[39m filtered_final_df[\u001b[39m'\u001b[39m\u001b[39mUser-ID\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLightGBM Recommendations for user\u001b[39m\u001b[39m\"\u001b[39m, example_user, \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, recommend_lgb(example_user))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBPR Recommendations for user\u001b[39m\u001b[39m\"\u001b[39m, example_user, \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, recommend_bpr(example_user))\n",
      "\u001b[1;32md:\\_Desktop\\CU-DG\\2025-SemA\\CS5481 Data Engineering\\BookRecommendation\\BookRecommendation\\Main.ipynb  15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m user_encoded \u001b[39m=\u001b[39m filtered_final_df[filtered_final_df[\u001b[39m'\u001b[39m\u001b[39mUser-ID\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m user_id][\u001b[39m'\u001b[39m\u001b[39muser_encoded\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m all_books \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(filtered_final_df[\u001b[39m'\u001b[39m\u001b[39mbook_encoded\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mnunique())\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m preds \u001b[39m=\u001b[39m lgb_model\u001b[39m.\u001b[39;49mpredict(pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39muser_encoded\u001b[39;49m\u001b[39m'\u001b[39;49m: [user_encoded] \u001b[39m*\u001b[39;49m \u001b[39mlen\u001b[39;49m(all_books), \u001b[39m'\u001b[39;49m\u001b[39mbook_encoded\u001b[39;49m\u001b[39m'\u001b[39;49m: all_books}))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m top_books \u001b[39m=\u001b[39m all_books[np\u001b[39m.\u001b[39margsort(preds)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][:n]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/_Desktop/CU-DG/2025-SemA/CS5481%20Data%20Engineering/BookRecommendation/BookRecommendation/Main.ipynb#Z1213sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m book_enc\u001b[39m.\u001b[39minverse_transform(top_books)\n",
      "File \u001b[1;32mc:\\Users\\86183\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py:4767\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   4765\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4766\u001b[0m         num_iteration \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 4767\u001b[0m \u001b[39mreturn\u001b[39;00m predictor\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m   4768\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m   4769\u001b[0m     start_iteration\u001b[39m=\u001b[39;49mstart_iteration,\n\u001b[0;32m   4770\u001b[0m     num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[0;32m   4771\u001b[0m     raw_score\u001b[39m=\u001b[39;49mraw_score,\n\u001b[0;32m   4772\u001b[0m     pred_leaf\u001b[39m=\u001b[39;49mpred_leaf,\n\u001b[0;32m   4773\u001b[0m     pred_contrib\u001b[39m=\u001b[39;49mpred_contrib,\n\u001b[0;32m   4774\u001b[0m     data_has_header\u001b[39m=\u001b[39;49mdata_has_header,\n\u001b[0;32m   4775\u001b[0m     validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   4776\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\86183\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py:1204\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[0;32m   1197\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pred_for_csc(\n\u001b[0;32m   1198\u001b[0m         csc\u001b[39m=\u001b[39mdata,\n\u001b[0;32m   1199\u001b[0m         start_iteration\u001b[39m=\u001b[39mstart_iteration,\n\u001b[0;32m   1200\u001b[0m         num_iteration\u001b[39m=\u001b[39mnum_iteration,\n\u001b[0;32m   1201\u001b[0m         predict_type\u001b[39m=\u001b[39mpredict_type,\n\u001b[0;32m   1202\u001b[0m     )\n\u001b[0;32m   1203\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m-> 1204\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__pred_for_np2d(\n\u001b[0;32m   1205\u001b[0m         mat\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m   1206\u001b[0m         start_iteration\u001b[39m=\u001b[39;49mstart_iteration,\n\u001b[0;32m   1207\u001b[0m         num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[0;32m   1208\u001b[0m         predict_type\u001b[39m=\u001b[39;49mpredict_type,\n\u001b[0;32m   1209\u001b[0m     )\n\u001b[0;32m   1210\u001b[0m \u001b[39melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[0;32m   1211\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pred_for_pyarrow_table(\n\u001b[0;32m   1212\u001b[0m         table\u001b[39m=\u001b[39mdata,\n\u001b[0;32m   1213\u001b[0m         start_iteration\u001b[39m=\u001b[39mstart_iteration,\n\u001b[0;32m   1214\u001b[0m         num_iteration\u001b[39m=\u001b[39mnum_iteration,\n\u001b[0;32m   1215\u001b[0m         predict_type\u001b[39m=\u001b[39mpredict_type,\n\u001b[0;32m   1216\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\86183\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py:1361\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     \u001b[39mreturn\u001b[39;00m preds, nrow\n\u001b[0;32m   1360\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__inner_predict_np2d(\n\u001b[0;32m   1362\u001b[0m         mat\u001b[39m=\u001b[39;49mmat,\n\u001b[0;32m   1363\u001b[0m         start_iteration\u001b[39m=\u001b[39;49mstart_iteration,\n\u001b[0;32m   1364\u001b[0m         num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[0;32m   1365\u001b[0m         predict_type\u001b[39m=\u001b[39;49mpredict_type,\n\u001b[0;32m   1366\u001b[0m         preds\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1367\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\86183\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py:1307\u001b[0m, in \u001b[0;36m_InnerPredictor.__inner_predict_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m   1305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length of pre-allocated predict array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1306\u001b[0m out_num_preds \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int64(\u001b[39m0\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m _safe_call(\n\u001b[0;32m   1308\u001b[0m     _LIB\u001b[39m.\u001b[39;49mLGBM_BoosterPredictForMat(\n\u001b[0;32m   1309\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle,\n\u001b[0;32m   1310\u001b[0m         ptr_data,\n\u001b[0;32m   1311\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(type_ptr_data),\n\u001b[0;32m   1312\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[0;32m   1313\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),\n\u001b[0;32m   1314\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(layout),\n\u001b[0;32m   1315\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(predict_type),\n\u001b[0;32m   1316\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(start_iteration),\n\u001b[0;32m   1317\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(num_iteration),\n\u001b[0;32m   1318\u001b[0m         _c_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_parameter),\n\u001b[0;32m   1319\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(out_num_preds),\n\u001b[0;32m   1320\u001b[0m         preds\u001b[39m.\u001b[39;49mctypes\u001b[39m.\u001b[39;49mdata_as(ctypes\u001b[39m.\u001b[39;49mPOINTER(ctypes\u001b[39m.\u001b[39;49mc_double)),\n\u001b[0;32m   1321\u001b[0m     )\n\u001b[0;32m   1322\u001b[0m )\n\u001b[0;32m   1323\u001b[0m \u001b[39mif\u001b[39;00m n_preds \u001b[39m!=\u001b[39m out_num_preds\u001b[39m.\u001b[39mvalue:\n\u001b[0;32m   1324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length for predict results\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\86183\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py:313\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;31mLightGBMError\u001b[0m: The number of features in data (2) is not the same as it was in training data (8).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "# --- Book Recommendation: Implement using defined algorithms ---\n",
    "# Re-fit LabelEncoder for books (if not already)\n",
    "book_enc = LabelEncoder()\n",
    "book_enc.fit(filtered_final_df['Book-Title'])\n",
    "\n",
    "def recommend_cf(book_title, n=5):\n",
    "    if book_title not in book_enc.classes_:\n",
    "        return \"Book not found\"\n",
    "    book_id = book_enc.transform([book_title])[0]\n",
    "    similar_books = cf_similarity_df[book_id].sort_values(ascending=False)[1:n+1].index\n",
    "    return book_enc.inverse_transform(similar_books)\n",
    "\n",
    "def recommend_lgb(user_id, n=5):\n",
    "    # For a given user, predict ratings for all books and recommend top\n",
    "    if user_id not in filtered_final_df['User-ID'].values:\n",
    "        return \"User not found\"\n",
    "    user_encoded = filtered_final_df[filtered_final_df['User-ID'] == user_id]['user_encoded'].iloc[0]\n",
    "    all_books = np.arange(filtered_final_df['book_encoded'].nunique())\n",
    "    preds = lgb_model.predict(pd.DataFrame({'user_encoded': [user_encoded] * len(all_books), 'book_encoded': all_books}))\n",
    "    top_books = all_books[np.argsort(preds)[::-1][:n]]\n",
    "    return book_enc.inverse_transform(top_books)\n",
    "\n",
    "def recommend_bpr(user_id, n=5):\n",
    "    # For a given user, compute scores for all items using MF embeddings\n",
    "    if user_id not in filtered_final_df['User-ID'].values:\n",
    "        return \"User not found\"\n",
    "    user_encoded = filtered_final_df[filtered_final_df['User-ID'] == user_id]['user_encoded'].iloc[0]\n",
    "    all_books = np.arange(filtered_final_df['book_encoded'].nunique())\n",
    "    \n",
    "    # Use the new recommend_bpr_for_user function with mappings\n",
    "    recs = recommend_bpr_for_user(user_encoded, bpr_model, all_books, bpr_user_mapping, bpr_item_mapping, n=n)\n",
    "    \n",
    "    if len(recs) == 0:\n",
    "        return \"No recommendations available (user or books not in training set)\"\n",
    "    \n",
    "    return book_enc.inverse_transform(recs)\n",
    "\n",
    "# Example: Recommend using CF (given book title)\n",
    "example_book = filtered_final_df['Book-Title'].iloc[0]\n",
    "print(\"CF Recommendations for\", example_book, \":\", recommend_cf(example_book))\n",
    "\n",
    "# Example: Recommend for a user using LightGBM and BPR\n",
    "example_user = filtered_final_df['User-ID'].iloc[0]\n",
    "print(\"LightGBM Recommendations for user\", example_user, \":\", recommend_lgb(example_user))\n",
    "print(\"BPR Recommendations for user\", example_user, \":\", recommend_bpr(example_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da621bb1",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "\n",
    "\n",
    "### 1. \n",
    "- ****`MIN_BOOK_RATINGS``MIN_USER_RATINGS`\n",
    "- ****\n",
    "- ****/\n",
    "\n",
    "### 2. \n",
    "- ****\n",
    "- ****LightGBM\n",
    "- ****NeuMFDeepFM\n",
    "\n",
    "### 3. \n",
    "- **K**K5, 10, 20\n",
    "- **Hit Rate**\n",
    "- ****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f989548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =====  =====\n",
    "# \n",
    "\n",
    "# 1: \n",
    "# MIN_BOOK_RATINGS = 50  # 10050\n",
    "# MIN_USER_RATINGS = 25  # 5025\n",
    "\n",
    "# 2: K\n",
    "# K5, 10, 20, 50\n",
    "# KRecallPrecision\n",
    "\n",
    "# 3: \n",
    "def hybrid_recommend(cf_recs, lgb_recs, bpr_recs, weights=[0.4, 0.3, 0.3], n=10):\n",
    "    \"\"\"\n",
    "    \n",
    "    weights: [CF, LightGBM, BPR]\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # \n",
    "    item_scores = Counter()\n",
    "    \n",
    "    # CF\n",
    "    for i, item in enumerate(cf_recs):\n",
    "        item_scores[item] += weights[0] * (len(cf_recs) - i) / len(cf_recs)\n",
    "    \n",
    "    # LightGBM\n",
    "    for i, item in enumerate(lgb_recs):\n",
    "        item_scores[item] += weights[1] * (len(lgb_recs) - i) / len(lgb_recs)\n",
    "    \n",
    "    # BPR\n",
    "    for i, item in enumerate(bpr_recs):\n",
    "        item_scores[item] += weights[2] * (len(bpr_recs) - i) / len(bpr_recs)\n",
    "    \n",
    "    # top N\n",
    "    top_items = [item for item, _ in item_scores.most_common(n)]\n",
    "    return top_items\n",
    "\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efddaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and data saved to 'models' directory.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create a 'models' directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save CF similarity matrix\n",
    "pickle.dump(cf_similarity_df, open('models/cf_similarity.pkl', 'wb'))\n",
    "\n",
    "# Save LightGBM model\n",
    "lgb_model.save_model('models/lgb_model.txt')\n",
    "\n",
    "# Save BPR model (state dict)\n",
    "torch.save(bpr_model.state_dict(), 'models/bpr_model.pth')\n",
    "\n",
    "# Save BPR mappings\n",
    "pickle.dump(bpr_user_mapping, open('models/bpr_user_mapping.pkl', 'wb'))\n",
    "pickle.dump(bpr_item_mapping, open('models/bpr_item_mapping.pkl', 'wb'))\n",
    "\n",
    "# Save book encoder\n",
    "pickle.dump(book_enc, open('models/book_enc.pkl', 'wb'))\n",
    "\n",
    "# Save filtered dataframe (for user/book encodings and nunique counts)\n",
    "pickle.dump(filtered_final_df, open('models/filtered_df.pkl', 'wb'))\n",
    "\n",
    "print(\"Models and data saved to 'models' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0cd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c66db79440479cbf639cfc7d296a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Book Title:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd8cc37a3284935aa246689edb03eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Recommend', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1ef1706b484b2ea7882bac325bf902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Present as Interactive App (10% score) ---\n",
    "# Simple interactive widget in Notebook (for demo; deploy to Streamlit for full web app)\n",
    "\n",
    "book_input = widgets.Text(value='', description='Book Title:')\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_recommend(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        book = book_input.value\n",
    "        recs_cf = recommend_cf(book)\n",
    "        print(f\"CF Recommendations: {recs_cf}\")\n",
    "        # Add other algorithms if needed\n",
    "\n",
    "recommend_button = widgets.Button(description=\"Recommend\")\n",
    "recommend_button.on_click(on_recommend)\n",
    "\n",
    "display(book_input, recommend_button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
